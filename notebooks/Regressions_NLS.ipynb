{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize, least_squares\n",
    "from scipy.stats import norm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "cimport numpy as np\n",
    "cimport cython\n",
    "\n",
    "cpdef np.ndarray cnorm(np.ndarray[double] x):\n",
    "    \n",
    "    cdef double e = 2.7182818284590452353602874\n",
    "    cdef double pi = 3.14159265358979323846 \n",
    "    \n",
    "    return (1/np.sqrt(2*pi))*(e**(-np.multiply(x, x)/2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CE_1_cy(Y, X, arg, r):\n",
    "    \n",
    "    n_arg = np.shape(arg)[0]\n",
    "    n = np.shape(X)[0]\n",
    "    h = (n**(-r)) * np.std(X, axis = 0, ddof = 1)\n",
    "    e = np.zeros((n_arg, 1))\n",
    "    \n",
    "    for j in range(0, n_arg):\n",
    "        temp = np.array(np.divide((arg[j] - X), h)).flatten()\n",
    "        k = np.divide(cnorm(temp), h)\n",
    "        k = np.prod(k, axis = 0).T  \n",
    "        e[j] = (Y.T*k/n)/np.mean(k)\n",
    "        \n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming function\n",
    "def trim(X, percent):\n",
    "    \n",
    "    alpha = (1 - percent)/2\n",
    "    n, k = np.shape(X)\n",
    "    t_ind = np.zeros((n, k))\n",
    "    \n",
    "    for i in range(0, k):\n",
    "        upper_bd = np.percentile(X[:,i], (1 - alpha)*100)\n",
    "        lower_bd = np.percentile(X[:,i], (alpha)*100)\n",
    "        t_ind[:, i] = [int(lower_bd < x < upper_bd) for x in X[:,i]]\n",
    "        \n",
    "    return np.prod(t_ind, axis = 1)\n",
    "\n",
    "# Conditional Expectation\n",
    "def CE_1(Y, X, arg, r):\n",
    "    \n",
    "    n_arg = np.shape(arg)[0]\n",
    "    n = np.shape(X)[0]\n",
    "    h = (n**(-r)) * np.std(X, axis = 0, ddof = 1)\n",
    "    e = np.zeros((n_arg, 1))\n",
    "    \n",
    "    for j in range(0, n_arg):\n",
    "        k = np.divide(norm.pdf(np.divide((arg[j] - X), h)), h)\n",
    "        k = np.prod(k, axis = 1)   \n",
    "        e[j] = (Y.T*k/n)/np.mean(k)\n",
    "        \n",
    "    return e\n",
    "\n",
    "# Semiparametric Least Squares objective\n",
    "def SLS_1(b, Y, X, X_ind):\n",
    "    \n",
    "    v = X * np.matrix(b).T\n",
    "    EY = CE_1_cy(Y, v, v, 1/5)\n",
    "    residual = np.power((Y - EY), 2)\n",
    "    \n",
    "    return (-0.5 * np.matrix(X_ind)*residual)\n",
    "\n",
    "# Regress Y on X with SLS\n",
    "def run_semiparametric_regression(Y, X, guess, trim_percent = 0.98, xtol = 0.001, maxiter = 1):\n",
    "    \n",
    "    obj_f = lambda x_0: -SLS_1(np.append(np.array([1]), x_0), Y, X, trim(X, 0.98))[0,0]\n",
    "    print('    Running LS...')\n",
    "    result = least_squares(obj_f, list(np.array(guess).flatten()), xtol = xtol)\n",
    "    print('    BFGS...')\n",
    "    result = minimize(obj_f, result.x, method='BFGS', options = {'maxiter': maxiter})\n",
    "    return result\n",
    "\n",
    "# Hessian to Covariance matrix\n",
    "def convert_hessian_to_cov(Y, X, results):\n",
    "    \n",
    "    sigma_2_hat = np.mean(np.power(Y - X*np.matrix(results.x).T, 2))\n",
    "    return results.hess_inv * sigma_2_hat\n",
    "\n",
    "# Marginal effects at a point using CE_1\n",
    "def compute_marginal_effect(Y, X, ind, point, beta, delta = 0.01):\n",
    "\n",
    "    point_nudge = np.copy(point)\n",
    "    point_nudge[0, ind] = point_nudge[0, ind] + delta\n",
    "    point_nudge = np.matrix(point_nudge)\n",
    "    \n",
    "    v_hat = X*beta\n",
    "    v_hat_avg = point*beta\n",
    "    v_hat_avg_nudge = point_nudge*beta\n",
    "    \n",
    "    return np.asscalar(CE_1(Y, v_hat, v_hat_avg_nudge, 1/5) - CE_1(Y, v_hat, v_hat_avg, 1/5))/delta\n",
    "\n",
    "# Range of marginal effects \n",
    "def calculate_me_range(Y, X, result, ind, point, delta = .001, delta_range = [0.0001, 0.01], parameter_range = [0, 0.014], n_1 = 200, n_2 = 5):\n",
    "\n",
    "    beta = np.matrix(result.x).T\n",
    "    \n",
    "    me_results = np.zeros(shape = (n_1, 2, n_2))\n",
    "    \n",
    "    linspace_1 = np.linspace(parameter_range[0], parameter_range[1], num = n_1)\n",
    "    linspace_2 = np.linspace(delta_range[0], delta_range[1], num = n_2)\n",
    "    \n",
    "    for j in range(0, n_2):\n",
    "\n",
    "        delta = linspace_2[j]\n",
    "        #primp_avgt = np.linspace(0.001, 0.5, num = n_2)[j]\n",
    "\n",
    "        for i in range(0, n_1):\n",
    "  \n",
    "            point_temp = np.copy(point)\n",
    "            point_temp[0, ind] = linspace_1[i]\n",
    "            \n",
    "            me_vec = compute_marginal_effect(Y, X, ind, point_temp, beta, delta = delta)\n",
    "\n",
    "            me_results[i,:,j] = np.array([linspace_1[i], np.asscalar(me_vec)])\n",
    "            \n",
    "    return me_results   \n",
    "\n",
    "# T-stats with first coefficient fixed\n",
    "def find_tstats(Y, X, results):\n",
    "    \n",
    "    V = convert_hessian_to_cov(Y, X, results)\n",
    "\n",
    "    n = np.shape(results.x)[0]\n",
    "    theta = results.x/results.x[0]\n",
    "    t_stats = np.zeros(shape = (n))\n",
    "    t_stats[0] = np.nan # first t-stat is unknown\n",
    "\n",
    "    for i in range(1, n):\n",
    "        t_stats[i] = theta[i] / np.sqrt(V[i,i])\n",
    "\n",
    "    return t_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 607,
   "metadata": {},
   "outputs": [],
   "source": [
    "workbook_file_loc = '../analysis/results/semiparametric_regressions_paid_Other.xlsx'\n",
    "sample_query = 'Rebate_Dummy == 1 & Exchange == \"Other\"'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 608,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = pd.read_csv('../data/processed/regression_data_levels_demeaned.csv').dropna()\n",
    "data_df['PrImp_Pct_Rebate_Dummy'] = data_df['PrImp_Pct'] * data_df['Rebate_Dummy']\n",
    "data_df['PrImp_AvgAmt_Rebate_Dummy'] = data_df['PrImp_AvgAmt'] * data_df['Rebate_Dummy']\n",
    "data_df['PrImp_ExpAmt_Rebate_Dummy'] = data_df['PrImp_ExpAmt'] * data_df['Rebate_Dummy']\n",
    "data_df['PrImp_AvgT_Rebate_Dummy'] = data_df['PrImp_AvgT'] * data_df['Rebate_Dummy']\n",
    "data_df['All_AvgT_Rebate_Dummy'] = data_df['All_AvgT'] * data_df['Rebate_Dummy']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 609,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Centers: ['ARCA' 'BNYC' 'CDRG' 'EDGX' 'FBCO' 'G1ES' 'SGMA' 'UBSS' 'VRTU']\n",
      "Brokers: ['Barclays Capital' 'Credit Suisse' 'Deutsche' 'Boenning Scattergood'\n",
      " 'Edward Jones' 'AXA' 'COR Clearing' 'DA Davidson' 'Euro Pacific Capital'\n",
      " 'LPL' 'Aurora Capital' 'Corporate Investment Group' 'E1 Asset Mgmt'\n",
      " 'Elish Elish' 'Bull Market Securities' 'Fifth Third']\n",
      "Samples: 350\n",
      "Sparsity: 27.71%\n"
     ]
    }
   ],
   "source": [
    "############### Test\n",
    "drop_mktctrs = ['AQUA', 'DBAB', 'CITI']\n",
    "drop_brokers = ['Securities America', 'Financorp Group', 'Cowen Execution']\n",
    "\n",
    "data_df = data_df[data_df['MarketCenter'].apply(lambda x: x not in drop_mktctrs)]\n",
    "data_df = data_df[data_df['Broker'].apply(lambda x: x not in drop_brokers)]\n",
    "\n",
    "print('Market Centers: ', end = '') \n",
    "print(data_df['MarketCenter'].unique())\n",
    "\n",
    "print('Brokers: ', end = '') \n",
    "print(data_df['Broker'].unique())\n",
    "\n",
    "\n",
    "sample_frac = 1 # None => All obs\n",
    "data_df = data_df.sample(frac = sample_frac).query(sample_query)\n",
    "\n",
    "print('Samples: %d' % data_df.shape[0])\n",
    "print('Sparsity: %0.2f%%' % (100*data_df.query('MktShare == 0').shape[0] / data_df.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regressions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 610,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fits\n",
    "fit1_formula = 'MktShare ~ PrImp_Pct + PrImp_AvgAmt + PrImp_AvgT'\n",
    "fit2_formula = 'MktShare ~ PrImp_ExpAmt + PrImp_AvgT'\n",
    "fit3_formula = 'MktShare ~ PrImp_Pct + PrImp_AvgAmt + All_AvgT'\n",
    "fit4_formula = 'MktShare ~ PrImp_ExpAmt + All_AvgT'\n",
    "\n",
    "# fit1_formula = 'MktShare ~ PrImp_Pct + PrImp_Pct_Rebate_Dummy + PrImp_AvgAmt + PrImp_AvgAmt_Rebate_Dummy + PrImp_AvgT + PrImp_AvgT_Rebate_Dummy'\n",
    "# fit2_formula = 'MktShare ~ PrImp_ExpAmt + PrImp_ExpAmt_Rebate_Dummy + PrImp_AvgT + PrImp_AvgT_Rebate_Dummy'\n",
    "# fit3_formula = 'MktShare ~ PrImp_Pct + PrImp_Pct_Rebate_Dummy + PrImp_AvgAmt + PrImp_AvgAmt_Rebate_Dummy + All_AvgT + All_AvgT_Rebate_Dummy'\n",
    "# fit4_formula = 'MktShare ~ PrImp_ExpAmt + PrImp_ExpAmt_Rebate_Dummy + All_AvgT + All_AvgT_Rebate_Dummy'\n",
    "\n",
    "\n",
    "formulaCols = lambda x: x.replace(' ', '').replace('~', '+').split('+') \n",
    "fit_formulae = [fit1_formula, fit2_formula, fit3_formula, fit4_formula]\n",
    "fit_formulae = [formulaCols(x) for x in fit_formulae]\n",
    "\n",
    "# Store results\n",
    "fit_results = [None] * len(fit_formulae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 611,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Regressing with fit 0...\n",
      "    Running LS...\n",
      "    BFGS...\n",
      "Regressing with fit 1...\n",
      "    Running LS...\n",
      "    BFGS...\n",
      "Regressing with fit 2...\n",
      "    Running LS...\n",
      "    BFGS...\n",
      "Regressing with fit 3...\n",
      "    Running LS...\n",
      "    BFGS...\n",
      "Complete\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, len(fit_formulae)):\n",
    "    \n",
    "    ## Get results\n",
    "    print('Regressing with fit %d...' % i )\n",
    "    \n",
    "    data = data_df[fit_formulae[i]]\n",
    "    X = np.matrix(data)[:, 1:]\n",
    "    Y = np.matrix(data)[:, 0]\n",
    "\n",
    "    guess = X[1, 1:]\n",
    "    results = run_semiparametric_regression(Y, X, guess, xtol = .001, maxiter = 50)\n",
    "    \n",
    "    fit_results[i] = results\n",
    "    \n",
    "    ## Update results\n",
    "    # Normalize results with first coefficient\n",
    "    fit_results[i].x = np.append(1, fit_results[i].x)\n",
    "    \n",
    "    # Add dictionary of coefficients \n",
    "    fit_results[i].coeffs  = {fit_formulae[i][1:][j]: fit_results[i].x[j] for j in range(0, len(fit_formulae[i])-1)}\n",
    "    \n",
    "    # Add dictionary of standard errors \n",
    "    V = convert_hessian_to_cov(Y, X, fit_results[i])\n",
    "    fit_results[i].stderrs = {fit_formulae[i][1:][j]: np.sqrt(V[j-1,j-1]) for j in range(1, len(fit_formulae[i])-1)}\n",
    "    fit_results[i].stderrs[fit_formulae[i][1:][0]] = np.nan\n",
    "    \n",
    "print('Complete')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 612,
   "metadata": {},
   "outputs": [],
   "source": [
    "# marginal effects for each var with others at percentiles\n",
    "\n",
    "delta = .001\n",
    "\n",
    "for i in range(0, len(fit_formulae)):\n",
    "    \n",
    "    data = data_df[fit_formulae[i]]\n",
    "    X = np.matrix(data)[:, 1:]\n",
    "    Y = np.matrix(data)[:, 0]\n",
    "    \n",
    "    fit_results[i].marginal_effects = {}\n",
    "    \n",
    "    for j in range(0, len(fit_results[i].x)):  \n",
    "        \n",
    "        temp_dict = {}\n",
    "        \n",
    "        for percentile in range(20, 81, 20):\n",
    "\n",
    "            X_percentile = np.percentile(X, percentile, axis = 0)\n",
    "            \n",
    "            temp_dict[percentile] = compute_marginal_effect(Y, X, j, np.matrix(X_percentile), np.matrix(fit_results[i].x).T, delta = delta)\n",
    "            \n",
    "        fit_results[i].marginal_effects[fit_formulae[i][j+1]] = temp_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 613,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import Workbook, load_workbook, utils\n",
    "from openpyxl.styles import Alignment, Font\n",
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 614,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sig_stars(coeff, stderr, p_value_labels):\n",
    "    t_stat = coeff/stderr\n",
    "    p_val  = 1 - norm.cdf(np.abs(t_stat))\n",
    "    below_ind = np.where([p_val < x for x in p_value_labels.keys()])[0]\n",
    "    below_vals = [list(p_value_labels.keys())[i] for i in below_ind]\n",
    "    if not below_vals:\n",
    "        return ''\n",
    "    else:\n",
    "        min_p_val = np.min(below_vals)\n",
    "        return p_value_labels[min_p_val]\n",
    "\n",
    "# Params\n",
    "p_value_labels = {0.05: '*', 0.01: '**', 0.001: '***'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open workbook\n",
    "wb = Workbook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 616,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb.create_sheet(title = 'Summary')\n",
    "ws['B2'] = 'n'\n",
    "ws['B3'] = data_df.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coefficient Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 617,
   "metadata": {},
   "outputs": [],
   "source": [
    "ws = wb.create_sheet(title = 'Coefficient Results')\n",
    "ws.column_dimensions[\"B\"].width = 30\n",
    "\n",
    "## Label regressors \n",
    "\n",
    "# Get regressors besides for market share\n",
    "fit_regressors = sorted(list(set(sum(fit_formulae, []))-set(['MktShare'])))\n",
    "fit_regressors\n",
    "\n",
    "regressor_cells = {}\n",
    "\n",
    "# First label's row\n",
    "regressor_label_row = 4\n",
    "\n",
    "for i in range(0, len(fit_regressors)):\n",
    "\n",
    "    cell = 'B' + str(regressor_label_row)\n",
    "   \n",
    "    ws[cell] = fit_regressors[i]\n",
    "    ws[cell].alignment = Alignment(horizontal = 'right')\n",
    "    ws[cell].font = Font(bold = True)\n",
    "    \n",
    "    regressor_cells[fit_regressors[i]] = regressor_label_row\n",
    "    regressor_label_row += 2\n",
    "\n",
    "## Label regressand\n",
    "start_cell = 'C2'\n",
    "end_cell   = string.ascii_uppercase[2*len(fit_results)] + '2'\n",
    "\n",
    "ws.merge_cells(start_cell + ':' + end_cell)\n",
    "\n",
    "ws[start_cell] = 'MktShare'\n",
    "ws[start_cell].alignment = Alignment(horizontal = 'center')\n",
    "ws[start_cell].font = Font(bold = True)\n",
    "\n",
    "## Label fits\n",
    "for i in range(0, len(fit_results)):\n",
    "    \n",
    "    cell_row = 3\n",
    "    cell_col = string.ascii_uppercase[2*i + 2]\n",
    "    cell = cell_col + str(cell_row)\n",
    "    \n",
    "    ws[cell] = 'Fit ' + str(i+1)\n",
    "    ws[cell].alignment = Alignment(horizontal = 'center')\n",
    "    ws[cell].font = Font(underline = 'single')\n",
    "    \n",
    "    # adjust cell widths\n",
    "    ws.column_dimensions[cell_col].width = 15\n",
    "    ws.column_dimensions[string.ascii_uppercase[2*i + 3]].width = 5\n",
    "\n",
    "## Enter results\n",
    "for i in range(0, len(fit_results)):\n",
    "    \n",
    "    fit_column = string.ascii_uppercase[2*i + 2]\n",
    "    \n",
    "    for regressor in fit_results[i].coeffs.keys():\n",
    "        \n",
    "        coeff = fit_results[i].coeffs[regressor]\n",
    "        stderr = fit_results[i].stderrs[regressor]\n",
    "        \n",
    "        regressor_label_row = regressor_cells[regressor]\n",
    "        cell = fit_column + str(regressor_label_row)\n",
    "        cell_below = fit_column + str(regressor_label_row + 1)\n",
    "        \n",
    "#         if coeff == 1: \n",
    "#             coeff = str(np.round(coeff, decimals = 4))\n",
    "#         else:\n",
    "        coeff = str(np.round(coeff, decimals = 4)) + get_sig_stars(coeff, stderr, p_value_labels)\n",
    "        \n",
    "        ws[cell] = coeff\n",
    "        ws[cell].alignment = Alignment(horizontal = 'center')\n",
    "        \n",
    "        ws[cell_below] = stderr\n",
    "        ws[cell_below].alignment = Alignment(horizontal = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Marginal Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 618,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up table\n",
    "for i in range(0, len(fit_results)):\n",
    "    \n",
    "    ws = wb.create_sheet(title = 'Fit ' + str(i+1) +' Marginal Effects')\n",
    "    ws.column_dimensions[\"B\"].width = 30\n",
    "    \n",
    "    fit_i_regressors = list(fit_results[i].marginal_effects.keys())\n",
    "    percentiles = sorted(list((next(iter(fit_results[i].marginal_effects.values()))).keys()))\n",
    "    \n",
    "    ## Label regressors\n",
    "    \n",
    "    # First label's row\n",
    "    regressor_label_row = 4\n",
    "    \n",
    "    regressor_cells = {}\n",
    "\n",
    "    for j in range(0, len(fit_i_regressors)):\n",
    "\n",
    "        cell = 'B' + str(regressor_label_row)\n",
    "\n",
    "        ws[cell] = fit_i_regressors[j]\n",
    "        ws[cell].alignment = Alignment(horizontal = 'right')\n",
    "        ws[cell].font = Font(bold = True)\n",
    "\n",
    "        regressor_cells[fit_i_regressors[j]] = regressor_label_row\n",
    "        regressor_label_row += 2\n",
    "        \n",
    "    ## Table title label\n",
    "    start_cell = 'C2'\n",
    "    end_cell   = string.ascii_uppercase[2*len(percentiles)] + '2'\n",
    "\n",
    "    ws.merge_cells(start_cell + ':' + end_cell)\n",
    "\n",
    "    ws[start_cell] = 'Marginal Effects (MktShare)'\n",
    "    ws[start_cell].alignment = Alignment(horizontal = 'center')\n",
    "    ws[start_cell].font = Font(bold = True)\n",
    "    \n",
    "    ## Label percentiles\n",
    "    for j in range(0, len(percentiles)):\n",
    "        \n",
    "        cell_row = 3\n",
    "        cell_col = string.ascii_uppercase[2*j + 2]\n",
    "        cell = cell_col + str(cell_row)\n",
    "\n",
    "        ws[cell] = 'Pct ' + str(percentiles[j])\n",
    "        ws[cell].alignment = Alignment(horizontal = 'center')\n",
    "        ws[cell].font = Font(underline = 'single')\n",
    "        \n",
    "        # adjust cell widths\n",
    "        ws.column_dimensions[cell_col].width = 15\n",
    "        ws.column_dimensions[string.ascii_uppercase[2*j + 3]].width = 5\n",
    "\n",
    "    ## Enter results\n",
    "    for regressor in fit_results[i].marginal_effects.keys():\n",
    "    \n",
    "        me_pct_dict = fit_results[i].marginal_effects[regressor]\n",
    "        \n",
    "        for k in range(0, len(percentiles)):\n",
    "\n",
    "            pct_col = string.ascii_uppercase[2*k + 2]    \n",
    "            cell = pct_col + str(regressor_cells[regressor])\n",
    "\n",
    "            ws[cell] = np.round(fit_results[i].marginal_effects[regressor][percentiles[k]], decimals = 6)\n",
    "            ws[cell].alignment = Alignment(horizontal = 'center')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Close"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 619,
   "metadata": {},
   "outputs": [],
   "source": [
    "del wb['Sheet']\n",
    "wb.save(workbook_file_loc)\n",
    "wb.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3490, 50)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Credit Suisse', 'Deutsche', 'Cowen Execution', 'Barclays Capital',\n",
       "       'Securities America', 'Boenning Scattergood', 'Edward Jones',\n",
       "       'Financorp Group', 'AXA', 'COR Clearing', 'DA Davidson',\n",
       "       'Euro Pacific Capital', 'LPL', 'Aurora Capital',\n",
       "       'Corporate Investment Group', 'E1 Asset Mgmt', 'Elish Elish',\n",
       "       'Bull Market Securities', 'Fifth Third'], dtype=object)"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df = pd.read_csv('../data/processed/regression_data_levels_demeaned.csv')\n",
    "print(data_df.shape)\n",
    "data_df['Broker'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "def t_stats_from_fit(fit):\n",
    "    stderrs = dict(fit.HC0_se)\n",
    "    coeffs  = dict(fit.params)\n",
    "    \n",
    "    t_stats = {}\n",
    "    \n",
    "    for key in coeffs.keys():\n",
    "        t_stats[key] = coeffs[key] / stderrs[key]\n",
    "        \n",
    "    return t_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 504,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Credit Suisse, 1\n",
      "    Quality index: -0.34068441949092554\n",
      "Deutsche, 1\n",
      "    Quality index: 0.04625936512448381\n",
      "Cowen Execution, 0\n",
      "    Quality index: nan\n",
      "Barclays Capital, 1\n",
      "    Quality index: -3.4508041859105765\n",
      "Securities America, 0\n",
      "    Quality index: -3.8380299566864595\n",
      "Boenning Scattergood, 1\n",
      "    Quality index: 0.36943629180953996\n",
      "Edward Jones, 0\n",
      "    Quality index: 10.794651745540776\n",
      "Financorp Group, 0\n",
      "    Quality index: -1.3270864333776446\n",
      "AXA, 0\n",
      "    Quality index: 4.495999746010994\n",
      "COR Clearing, 0\n",
      "    Quality index: -0.15747740448787512\n",
      "DA Davidson, 0\n",
      "    Quality index: -0.46620368231115245\n",
      "Euro Pacific Capital, 0\n",
      "    Quality index: 3.7832277174273132\n",
      "LPL, 0\n",
      "    Quality index: 3.9512002550691303\n",
      "Aurora Capital, "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "    Quality index: 3.316970328293905\n",
      "Corporate Investment Group, 0\n",
      "    Quality index: 1.4136269229532723\n",
      "E1 Asset Mgmt, 0\n",
      "    Quality index: -0.176881986832798\n",
      "Elish Elish, 0\n",
      "    Quality index: 0.087776821961144\n",
      "Bull Market Securities, 0\n",
      "    Quality index: 5.456808694769659\n",
      "Fifth Third, 0\n",
      "    Quality index: -0.23514203261056665\n"
     ]
    }
   ],
   "source": [
    "res_df = pd.DataFrame()\n",
    "\n",
    "for broker in data_df['Broker'].unique():\n",
    "    \n",
    "    print(broker, end = ', ')\n",
    "    print(str(data_df[data_df['Broker'].apply(lambda x: x == broker)].iloc[0]['Rebate_Dummy']))\n",
    "    \n",
    "    fit = sm.ols(formula = 'MktShare ~ PrImp_Pct + PrImp_AvgAmt + PrImp_AvgT', data = data_df[data_df['Broker'].apply(lambda x: x == broker)]\n",
    "        ).fit()\n",
    "    \n",
    "    t_stats = t_stats_from_fit(fit)\n",
    "    \n",
    "    print('    Quality index: ' + str(t_stats['PrImp_AvgAmt'] + t_stats['PrImp_Pct'] - t_stats['PrImp_AvgT']))\n",
    "    \n",
    "    res_df = res_df.append({'Broker': broker, \n",
    "                            'Rebate': data_df[data_df['Broker'].apply(lambda x: x == broker)].iloc[0]['Rebate_Dummy'],\n",
    "                           'Qual': (t_stats['PrImp_AvgAmt'] + t_stats['PrImp_Pct'] - t_stats['PrImp_AvgT'])}, ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Broker</th>\n",
       "      <th>Qual</th>\n",
       "      <th>Rebate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Securities America</td>\n",
       "      <td>-3.838030</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Barclays Capital</td>\n",
       "      <td>-3.450804</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Financorp Group</td>\n",
       "      <td>-1.327086</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DA Davidson</td>\n",
       "      <td>-0.466204</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Credit Suisse</td>\n",
       "      <td>-0.340684</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Fifth Third</td>\n",
       "      <td>-0.235142</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>E1 Asset Mgmt</td>\n",
       "      <td>-0.176882</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>COR Clearing</td>\n",
       "      <td>-0.157477</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Deutsche</td>\n",
       "      <td>0.046259</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Elish Elish</td>\n",
       "      <td>0.087777</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Boenning Scattergood</td>\n",
       "      <td>0.369436</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Corporate Investment Group</td>\n",
       "      <td>1.413627</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Aurora Capital</td>\n",
       "      <td>3.316970</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Euro Pacific Capital</td>\n",
       "      <td>3.783228</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LPL</td>\n",
       "      <td>3.951200</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AXA</td>\n",
       "      <td>4.496000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bull Market Securities</td>\n",
       "      <td>5.456809</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Edward Jones</td>\n",
       "      <td>10.794652</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Cowen Execution</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Broker       Qual  Rebate\n",
       "4           Securities America  -3.838030     0.0\n",
       "3             Barclays Capital  -3.450804     1.0\n",
       "7              Financorp Group  -1.327086     0.0\n",
       "10                 DA Davidson  -0.466204     0.0\n",
       "0                Credit Suisse  -0.340684     1.0\n",
       "18                 Fifth Third  -0.235142     0.0\n",
       "15               E1 Asset Mgmt  -0.176882     0.0\n",
       "9                 COR Clearing  -0.157477     0.0\n",
       "1                     Deutsche   0.046259     1.0\n",
       "16                 Elish Elish   0.087777     0.0\n",
       "5         Boenning Scattergood   0.369436     1.0\n",
       "14  Corporate Investment Group   1.413627     0.0\n",
       "13              Aurora Capital   3.316970     0.0\n",
       "11        Euro Pacific Capital   3.783228     0.0\n",
       "12                         LPL   3.951200     0.0\n",
       "8                          AXA   4.496000     0.0\n",
       "17      Bull Market Securities   5.456809     0.0\n",
       "6                 Edward Jones  10.794652     0.0\n",
       "2              Cowen Execution        NaN     0.0"
      ]
     },
     "execution_count": 506,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_df.sort_values('Qual')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 501,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MarketCenter</th>\n",
       "      <th>MktShare</th>\n",
       "      <th>PrImp_ExpAmt</th>\n",
       "      <th>PrImp_AvgT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [MarketCenter, MktShare, PrImp_ExpAmt, PrImp_AvgT]\n",
       "Index: []"
      ]
     },
     "execution_count": 501,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_df.query('Broker == \"Cowen Execution\" & MktShare != 0')[['MarketCenter', 'MktShare', 'PrImp_ExpAmt', 'PrImp_AvgT']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opt test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtol = .1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Running LS...\n",
      "`xtol` termination condition is satisfied.\n",
      "Function evaluations 7, initial cost 1.4803e+02, final cost 1.4645e+02, first-order optimality 5.49e-01.\n",
      "17.114196558533862\n",
      "    BFGS...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "      fun: 17.11418627567715\n",
       " hess_inv: array([[2.49415125, 0.00629013],\n",
       "       [0.00629013, 0.00498528]])\n",
       "      jac: array([ 0.0320673 , -0.02669764])\n",
       "  message: 'Maximum number of iterations has been exceeded.'\n",
       "     nfev: 12\n",
       "      nit: 1\n",
       "     njev: 3\n",
       "   status: 1\n",
       "  success: False\n",
       "        x: array([-0.00482794,  0.01704187])"
      ]
     },
     "execution_count": 431,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_f = lambda x_0: -SLS_1(np.append(np.array([1]), x_0), Y, X, trim(X, 0.98))[0,0]\n",
    "print('    Running LS...')\n",
    "\n",
    "result1 = least_squares(obj_f, list(np.array(guess).flatten()), xtol = xtol, verbose = 1)\n",
    "print(obj_f(result1.x))\n",
    "\n",
    "print('    BFGS...')\n",
    "\n",
    "result = minimize(obj_f, result1.x, method='BFGS', options = {'maxiter': 1})\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Maximum number of iterations has been exceeded.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   direc: array([[1., 0.],\n",
       "       [0., 1.]])\n",
       "     fun: 17.064983988866448\n",
       " message: 'Maximum number of iterations has been exceeded.'\n",
       "    nfev: 29\n",
       "     nit: 1\n",
       "  status: 2\n",
       " success: False\n",
       "       x: array([-2.72747448,  0.01853702])"
      ]
     },
     "execution_count": 427,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minimize(obj_f, result1.x, method='Powell', options = {'disp': True, 'maxiter': 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01248077,  0.04367601],\n",
       "       [ 0.04367601, -0.02146611]])"
      ]
     },
     "execution_count": 430,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "\n",
    "hess = nd.Hessian(obj_f)(result.x)\n",
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<numdifftools.core.Hessian at 0x7f09e17053c8>"
      ]
     },
     "execution_count": 432,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_f = lambda x: x[0]*x[1]\n",
    "\n",
    "hess = nd.Hessian(test_f)\n",
    "hess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 434,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1.],\n",
       "       [1., 0.]])"
      ]
     },
     "execution_count": 434,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hess([1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "point = [1,1]\n",
    "\n",
    "test_f(point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17.114152046746145"
      ]
     },
     "execution_count": 442,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obj_f(np.array((result.x))*1.000001) / 1.000001**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 447,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 9.86717383, 20.07624032],\n",
       "       [20.07624032, -5.73694662]])"
      ]
     },
     "execution_count": 447,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.linalg.inv(np.array([[ 0.01248077,  0.04367601],[ 0.04367601, -0.02146611]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.01248077,  0.04367601],\n",
       "       [ 0.04367601, -0.02146611]])"
      ]
     },
     "execution_count": 446,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
